{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BASHA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BASHA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import heapq\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence is human like intelligence. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of reasoning machines. Learn from mistakes and successes. Artificial intelligence is related to reasoning in everyday situations.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = '''artificial intelligence is human like intelligence.\n",
    "                   It is the study of intelligent artificial agents.\n",
    "                   Science and engineering to produce intelligent machines.\n",
    "                   Solve problems and have intelligence.\n",
    "                   Related to intelligent behavior.\n",
    "                   Developing of reasoning machines.\n",
    "                   Learn from mistakes and successes.\n",
    "                   Artificial intelligence is related to reasoning in everyday situations.'''\n",
    "\n",
    "original_text =re.sub(r'\\s+',' ',original_text) # \\s fro space and + for one or more than one space\n",
    "\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    formatted_text = text.lower()\n",
    "    tokens = []  # storing each words of sentence with out stop words\n",
    "    for token in nltk.word_tokenize(formatted_text):\n",
    "        tokens.append(token)\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in string.punctuation]\n",
    "    formatted_text = ' '.join(element for element in tokens) # creating sentence without stop words and punctations\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence human like intelligence study intelligent artificial agents science engineering produce intelligent machines solve problems intelligence related intelligent behavior developing reasoning machines learn mistakes successes artificial intelligence related reasoning everyday situations\n"
     ]
    }
   ],
   "source": [
    "formatted_text = preprocess(original_text)\n",
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calualte_sentence_score(sentences, important_words,distance):\n",
    "    scores = []\n",
    "    sentence_index = 0\n",
    "    for sentence in [nltk.word_tokenize(sentence) for sentence in sentences]:\n",
    "        word_index=[]\n",
    "        for word in important_words:\n",
    "            try:\n",
    "                word_index.append(sentence.index(word))\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        word_index.sort()\n",
    "        \n",
    "        if len(word_index) == 0:\n",
    "            continue\n",
    "        \n",
    "        groups_list = []\n",
    "        group = [word_index[0]]\n",
    "        \n",
    "        i = 1\n",
    "        \n",
    "        while i < len(word_index):\n",
    "            if word_index[i] - word_index[i-1] < distance:\n",
    "                group.append(word_index[1])\n",
    "            else:\n",
    "                groups_list.append(group[:])\n",
    "                group = [word_index[i]]\n",
    "                \n",
    "            i +=1\n",
    "        groups_list.append(group)\n",
    "        \n",
    "        max_group_score = 0\n",
    "        \n",
    "        for g in groups_list:\n",
    "            \n",
    "            important_words_in_group = len(g)\n",
    "            total_words_in_group = g[-1] - g[0] + 1\n",
    "            score = 1.0 * important_words_in_group ** 2 / total_words_in_group\n",
    "            \n",
    "            if score > max_group_score :               \n",
    "                max_group_score = score\n",
    "                \n",
    "        scores.append((max_group_score, sentence_index))\n",
    "        sentence_index += 1\n",
    "    \n",
    "    return scores\n",
    "            \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarize(text, top_num_words, distance, number_of_sentences):\n",
    "    original_sentences = [sentence for sentence in nltk.sent_tokenize(text)]\n",
    "    \n",
    "    fromatted_sentences = [preprocess(original_sentence) for original_sentence in original_sentences]\n",
    "    \n",
    "    words = [word for sentence in fromatted_sentences for word in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    frequency = nltk.FreqDist(words)\n",
    "    \n",
    "    top_n_words= [word[0] for word in frequency.most_common(top_num_words)]\n",
    "        \n",
    "    sentenced_score = calualte_sentence_score(fromatted_sentences,top_n_words,distance)\n",
    "    \n",
    "    best_sentences = heapq.nlargest(number_of_sentences, sentenced_score)\n",
    "    \n",
    "    best_sentences = [original_sentences[i] for (score, i) in best_sentences]\n",
    "    summary = \" \".join(best_sentences)\n",
    "    \n",
    "    return summary  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learn from mistakes and successes. Related to intelligent behavior. Science and engineering to produce intelligent machines. It is the study of intelligent artificial agents. artificial intelligence is human like intelligence. Developing of reasoning machines. Solve problems and have intelligence.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summarize(original_text,5,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose\n",
    "g = Goose()\n",
    "url =  'https://www.reuters.com/world/americas/haitians-scramble-rescue-survivors-ruins-major-quake-2021-08-15/'\n",
    "article = g.extract(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Haiti\\'s Civil Protection Agency said the toll from the disaster had climbed to 1,297 and the hospitals that were still functioning were struggling to cope as some 5,700 people were injured. From the Vatican, Pope Francis urged the international community to show support swiftly. Colombia sent search and rescue personnel. \"They are affected but resilient. Haiti\\'s Prime Minister Ariel Henry, who flew to visit Les Cayes, praised the dignity shown by people there even in the midst of their suffering. Some 13,694 houses were destroyed, the civil protection agency said, suggesting the toll could rise further. Southwestern Haiti bore the brunt of the blow, especially in the region in and around the town of Les Cayes. PORT-AU-PRINCE, Aug 15 (Reuters) - Haiti\\'s hospitals were swamped on Sunday by thousands of injured residents after a devastating earthquake the day before killed at least 1,297 people as authorities raced to bring doctors to the worst-hit areas before a major storm hits. Footage of Saturday\\'s aftermath posted on social media showed residents reaching into narrow openings in piles of fallen masonry to pull shocked and distraught people from the debris of walls and roofs that had crumbled around them.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summarize(article.cleaned_text,5,2,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
